groups:
  - name: backend_alerts
    interval: 30s
    rules:
      # Alert khi p95 latency vượt 1 giây
      - alert: HighLatency
        expr: histogram_quantile(0.95, sum(rate(ktpm_backend_http_request_duration_seconds_bucket[5m])) by (le, route)) > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected on {{ $labels.route }}"
          description: "p95 latency is {{ $value }}s on route {{ $labels.route }}"

      # Alert khi error rate cao
      - alert: HighErrorRate
        expr: sum(rate(ktpm_backend_http_errors_total[5m])) by (route) > 0.1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate on {{ $labels.route }}"
          description: "Error rate is {{ $value }} errors/sec on {{ $labels.route }}"

      # Alert khi CPU usage cao
      - alert: HighCPUUsage
        expr: rate(ktpm_backend_process_cpu_user_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Backend CPU usage is high"
          description: "CPU usage is {{ $value }}%"

      # Alert khi memory usage cao
      - alert: HighMemoryUsage
        expr: (ktpm_backend_nodejs_heap_size_used_bytes / ktpm_backend_nodejs_heap_size_total_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Backend memory usage is high"
          description: "Heap usage is {{ $value }}%"

      # Alert khi event loop lag cao
      - alert: EventLoopLag
        expr: ktpm_backend_nodejs_eventloop_lag_seconds > 0.5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Event loop is lagging"
          description: "Event loop lag is {{ $value }}s"

      # Alert khi backend down
      - alert: BackendDown
        expr: up{job="backend"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Backend is down"
          description: "Backend service is not responding"

  # CI/CD Pipeline Alerts
  - name: cicd_alerts
    interval: 30s
    rules:
      # Alert khi CI build fail
      - alert: CIBuildFailed
        expr: ci_build_status == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "CI Build Failed: {{ $labels.workflow }} on {{ $labels.branch }}"
          description: "Build failed for workflow {{ $labels.workflow }} on branch {{ $labels.branch }} (Run ID: {{ $labels.run_id }})"

      # Alert khi test pass rate thấp
      - alert: LowTestPassRate
        expr: ci_test_pass_rate < 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Low Test Pass Rate: {{ $value }}%"
          description: "Test pass rate is {{ $value }}% for {{ $labels.workflow }} on {{ $labels.branch }}"

      # Alert khi có tests failed
      - alert: TestsFailed
        expr: ci_tests_failed > 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Tests Failed: {{ $value }} tests"
          description: "{{ $value }} tests failed in {{ $labels.workflow }} on {{ $labels.branch }}"

      # Alert khi test duration quá lâu
      - alert: SlowTestExecution
        expr: ci_test_duration_seconds > 120
        for: 1m
        labels:
          severity: info
        annotations:
          summary: "Slow Test Execution: {{ $value }}s"
          description: "Test execution took {{ $value }}s for {{ $labels.workflow }} (threshold: 120s)"

      # Alert khi coverage giảm
      - alert: CoverageDropped
        expr: ci_coverage_percentage < 70
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Code Coverage Dropped: {{ $value }}%"
          description: "Code coverage is {{ $value }}% (threshold: 70%) for {{ $labels.workflow }}"

      # Alert khi build liên tục fail
      - alert: ConsecutiveBuildFailures
        expr: count_over_time(ci_build_status{ci_build_status="0"}[30m]) >= 3
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Multiple Consecutive Build Failures"
          description: "3 or more builds have failed in the last 30 minutes for {{ $labels.workflow }}"
